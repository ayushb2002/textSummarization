{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Audio to text summarization.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNJOi02TnxOL7Fx5ePoqY5b",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ayushb2002/textSummarization/blob/main/Audio_to_text_summarization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Machine Learning algorithm for text summariation and notes making!"
      ],
      "metadata": {
        "id": "DX0j0xNifHaX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Vq3JWN_PdXj4"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import sklearn\n",
        "import seaborn as sns\n",
        "import os\n",
        "import nltk\n",
        "import nltk.corpus\n",
        "from IPython.display import Image\n",
        "# Identification of different figures of speech such as nouns, pronouns, verbs etc.\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cXileolnm4Nm",
        "outputId": "857cd5e1-d606-410f-ef7c-000d36e9932d"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('averaged_perceptron_tagger')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4xEgCBXQnY4d",
        "outputId": "230b8156-2a4e-40fc-96a4-13438e60159c"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TBuov4z5q8hr",
        "outputId": "bb2148fe-9145-4417-d0d6-f0d8e1e6bdf9"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('maxent_ne_chunker')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NuhV6zLysY-a",
        "outputId": "64e34754-e0f6-40e7-b469-7b0928c2d35e"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package maxent_ne_chunker to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping chunkers/maxent_ne_chunker.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('words')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SsZSTHnfseLo",
        "outputId": "aef86961-792c-4e1d-9eb1-56aec227ce20"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/words.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('movie_reviews')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UqIEG_jmwu3E",
        "outputId": "a8a99c99-855d-4b7b-e19a-475c87893308"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package movie_reviews to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/movie_reviews.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('wordnet')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wiltPqe2y7k-",
        "outputId": "a437b38d-42ec-4a4e-f48b-47a8202c2a8f"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import stopwords # for stopwords\n",
        "\n",
        "#stopwords.words(\"english\")"
      ],
      "metadata": {
        "id": "ydv8rwnpnmu5"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "para = \"Artificial intelligence (AI) refers to the simulation of human intelligence in machines that are programmed to think like humans and mimic their actions. The term may also be applied to any machine that exhibits traits associated with a human mind such as learning and problem-solving.\""
      ],
      "metadata": {
        "id": "DhOus9wiqAOe"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "AI_tokens = word_tokenize(para)"
      ],
      "metadata": {
        "id": "jWwWBOzoqKlm"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "punctuation = re.compile(r'[-.?!,:;()|0-9]')"
      ],
      "metadata": {
        "id": "1QKX2mDroF0p"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "post_punctuation = []\n",
        "for words in AI_tokens:\n",
        "  word = punctuation.sub(\"\", words)\n",
        "  if len(word)>0:\n",
        "    post_punctuation.append(word)"
      ],
      "metadata": {
        "id": "n4SVkr8KpaSk"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(post_punctuation), post_punctuation"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8b4rJD7FqnWA",
        "outputId": "72dedc76-0c4b-448a-b37d-a06e01249a93"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(45,\n",
              " ['Artificial',\n",
              "  'intelligence',\n",
              "  'AI',\n",
              "  'refers',\n",
              "  'to',\n",
              "  'the',\n",
              "  'simulation',\n",
              "  'of',\n",
              "  'human',\n",
              "  'intelligence',\n",
              "  'in',\n",
              "  'machines',\n",
              "  'that',\n",
              "  'are',\n",
              "  'programmed',\n",
              "  'to',\n",
              "  'think',\n",
              "  'like',\n",
              "  'humans',\n",
              "  'and',\n",
              "  'mimic',\n",
              "  'their',\n",
              "  'actions',\n",
              "  'The',\n",
              "  'term',\n",
              "  'may',\n",
              "  'also',\n",
              "  'be',\n",
              "  'applied',\n",
              "  'to',\n",
              "  'any',\n",
              "  'machine',\n",
              "  'that',\n",
              "  'exhibits',\n",
              "  'traits',\n",
              "  'associated',\n",
              "  'with',\n",
              "  'a',\n",
              "  'human',\n",
              "  'mind',\n",
              "  'such',\n",
              "  'as',\n",
              "  'learning',\n",
              "  'and',\n",
              "  'problemsolving'])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sent1 = \"John is eating a delicious cake\"\n",
        "sent1_tokens = word_tokenize(sent1)\n",
        "for token in sent1_tokens:\n",
        "  print(nltk.pos_tag([token]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cVsKqyhKqo-p",
        "outputId": "aaf2e283-a82d-452f-e2a6-e512317dfed1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('John', 'NNP')]\n",
            "[('is', 'VBZ')]\n",
            "[('eating', 'VBG')]\n",
            "[('a', 'DT')]\n",
            "[('delicious', 'JJ')]\n",
            "[('cake', 'NN')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk import ne_chunk"
      ],
      "metadata": {
        "id": "Q23BtXtmrOuT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "NE_sent = \"The US President stays in the white house\"\n",
        "NE_tokens = word_tokenize(NE_sent)\n",
        "NE_tags = nltk.pos_tag(NE_tokens)"
      ],
      "metadata": {
        "id": "alMyuTb4r5P1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "NE_ner = ne_chunk(NE_tags)\n",
        "print(NE_ner)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eSHaS2rCsHma",
        "outputId": "505b5f4e-4d36-4788-a9cb-f18ddbbfccd9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(S\n",
            "  The/DT\n",
            "  (ORGANIZATION US/NNP)\n",
            "  President/NNP\n",
            "  stays/VBZ\n",
            "  in/IN\n",
            "  the/DT\n",
            "  white/JJ\n",
            "  house/NN)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install ghostscript"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3mvpl8CxsWTh",
        "outputId": "0832df56-d313-4b05-e207-10df6743dd9d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ghostscript\n",
            "  Downloading ghostscript-0.7-py2.py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: setuptools>=38.6.0 in /usr/local/lib/python3.7/dist-packages (from ghostscript) (57.4.0)\n",
            "Installing collected packages: ghostscript\n",
            "Successfully installed ghostscript-0.7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Process of chunking\n",
        "\n",
        "newStr = \"The big cat ate the little mouse who was after the fresh cheese\"\n",
        "newToken = nltk.pos_tag(word_tokenize(newStr))\n",
        "newToken"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EIKEqpBOs9HB",
        "outputId": "6bbb812a-41ec-4bb1-ee89-5183980465cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('The', 'DT'),\n",
              " ('big', 'JJ'),\n",
              " ('cat', 'NN'),\n",
              " ('ate', 'VBD'),\n",
              " ('the', 'DT'),\n",
              " ('little', 'JJ'),\n",
              " ('mouse', 'NN'),\n",
              " ('who', 'WP'),\n",
              " ('was', 'VBD'),\n",
              " ('after', 'IN'),\n",
              " ('the', 'DT'),\n",
              " ('fresh', 'JJ'),\n",
              " ('cheese', 'NN')]"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a grammer which we want in chunk phrase \n",
        "\n",
        "grammer_np = r\"NP: {<DT>?<JJ>*<NN>}\""
      ],
      "metadata": {
        "id": "T0Nv2eiJt2K7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chunk_parser = nltk.RegexpParser(grammer_np)"
      ],
      "metadata": {
        "id": "e1TugWN-uSO6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chunk_result = chunk_parser.parse(newToken)\n",
        "chunk_result # Giving error as colab does not support this method. Run on system to avoid this error."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 418
        },
        "id": "T_hwWKq-uFDa",
        "outputId": "c5ddb4e8-be0e-4476-86db-880d21bbe941"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TclError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTclError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    336\u001b[0m             \u001b[0mmethod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_real_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_method\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    337\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 338\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    339\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/nltk/tree.py\u001b[0m in \u001b[0;36m_repr_png_\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    717\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutil\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCanvasFrame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minternals\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfind_binary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 719\u001b[0;31m         \u001b[0m_canvas_frame\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCanvasFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    720\u001b[0m         \u001b[0mwidget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtree_to_treesegment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_canvas_frame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0m_canvas_frame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_widget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwidget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/nltk/draw/util.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, parent, **kw)\u001b[0m\n\u001b[1;32m   1651\u001b[0m         \u001b[0;31m# If no parent was given, set up a top-level window.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1652\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mparent\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1653\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1654\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'NLTK'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1655\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'<Control-p>'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_to_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/tkinter/__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, screenName, baseName, className, useTk, sync, use)\u001b[0m\n\u001b[1;32m   2021\u001b[0m                 \u001b[0mbaseName\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbaseName\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2022\u001b[0m         \u001b[0minteractive\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2023\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_tkinter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscreenName\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbaseName\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclassName\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minteractive\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwantobjects\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0museTk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msync\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2024\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0museTk\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2025\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_loadtk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTclError\u001b[0m: no display name and no $DISPLAY environment variable"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Tree('S', [Tree('NP', [('The', 'DT'), ('big', 'JJ'), ('cat', 'NN')]), ('ate', 'VBD'), Tree('NP', [('the', 'DT'), ('little', 'JJ'), ('mouse', 'NN')]), ('who', 'WP'), ('was', 'VBD'), ('after', 'IN'), Tree('NP', [('the', 'DT'), ('fresh', 'JJ'), ('cheese', 'NN')])])"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer "
      ],
      "metadata": {
        "id": "FHaegwO0uW3G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(os.listdir(nltk.data.find(\"corpora\")))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Aw30rqgrwBym",
        "outputId": "28d02a94-ba57-47a0-cf8b-762692005ac9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['movie_reviews.zip', 'movie_reviews', 'stopwords.zip', 'stopwords', 'words', 'words.zip']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# To generate synonyms etc.\n",
        "\n",
        "from nltk.corpus import wordnet\n",
        "syns = wordnet.synsets(\"important\") \n",
        "  \n",
        "print(syns[0].name()) \n",
        "  \n",
        "print(syns[0].lemmas()[0].name()) \n",
        "  \n",
        "print(syns[0].definition()) \n",
        "  \n",
        "print(syns[0].examples())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nbO2_OXlxBZ-",
        "outputId": "184464a1-e611-4043-e986-fc7a1eef408c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "important.a.01\n",
            "important\n",
            "of great significance or value\n",
            "['important people', 'the important questions of the day']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models import Word2Vec\n",
        "import nltk\n",
        "# define training data\n",
        "content=\"\"\"Cake is a form of sweet food made from flour, sugar, and other ingredients, that is usually baked.\n",
        "In their oldest forms, cakes were modifications of bread, but cakes now cover a wide range of preparations that can be simple or elaborate, and that share features with other desserts such as pastries, meringues, custards, and pies.\"\"\"\n",
        "sentences=nltk.sent_tokenize(content)\n",
        "words=[]\n",
        "\n",
        "for i in sentences:\n",
        "    words.append(nltk.word_tokenize(i))\n",
        "\n",
        "# train model\n",
        "model = Word2Vec(words, min_count=1)\n",
        "\n",
        "# summarize the loaded model\n",
        "print(model)\n",
        "\n",
        "# summarize vocabulary\n",
        "word_vec_words = list(model.wv.vocab)\n",
        "print(word_vec_words)\n",
        "\n",
        "# access vector for one word\n",
        "print(model['sugar'])\n",
        "\n",
        "# save model\n",
        "model.save('model.bin')\n",
        "\n",
        "# load model\n",
        "new_model = Word2Vec.load('model.bin')\n",
        "print(new_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N4oCFOJFy32C",
        "outputId": "a10e4674-1081-4741-f0bc-f3a755b9d520"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Word2Vec(vocab=48, size=100, alpha=0.025)\n",
            "['Cake', 'is', 'a', 'form', 'of', 'sweet', 'food', 'made', 'from', 'flour', ',', 'sugar', 'and', 'other', 'ingredients', 'that', 'usually', 'baked', '.', 'In', 'their', 'oldest', 'forms', 'cakes', 'were', 'modifications', 'bread', 'but', 'now', 'cover', 'wide', 'range', 'preparations', 'can', 'be', 'simple', 'or', 'elaborate', 'share', 'features', 'with', 'desserts', 'such', 'as', 'pastries', 'meringues', 'custards', 'pies']\n",
            "[-1.0738604e-03 -3.5498452e-03 -3.3292570e-03  4.7651720e-03\n",
            "  2.1713910e-04 -2.5128417e-03 -1.4641852e-03  2.1422445e-03\n",
            " -3.1401056e-03 -3.8788847e-03  1.3065654e-04 -3.3815168e-03\n",
            "  2.0487199e-03 -4.9280291e-03 -4.0164446e-03 -2.4478142e-03\n",
            " -2.9044661e-03 -2.3760861e-03 -3.0464644e-03  3.9215842e-03\n",
            " -4.2540435e-04  3.7881292e-03 -4.0674102e-03  4.1024084e-04\n",
            " -3.5644886e-03 -4.1863038e-03  3.8727461e-03  2.8823775e-03\n",
            "  4.4398019e-03 -3.6213074e-03  2.0774538e-03 -1.4005350e-03\n",
            "  3.8649875e-03  1.8776137e-03  4.6833856e-03  1.4631861e-04\n",
            "  4.4669211e-04 -3.7273457e-03 -1.3573568e-03 -5.8109575e-04\n",
            "  2.8363846e-03  1.8257885e-04 -2.9358759e-03  1.9164056e-05\n",
            " -3.4764742e-03 -1.9962180e-03 -8.9840568e-04  2.9875448e-03\n",
            "  5.9254467e-04  4.7319257e-03  1.3392011e-03  1.0233321e-03\n",
            " -4.3650263e-04  4.7229086e-03 -4.1789347e-03 -3.4805718e-03\n",
            " -2.8987699e-03  1.9229569e-03  4.7478583e-03 -1.8815865e-03\n",
            " -3.3273347e-05 -3.2134615e-03 -1.4566155e-03  4.9144472e-03\n",
            " -8.6372835e-04  2.4164554e-03 -5.2593125e-04  2.3595914e-03\n",
            "  2.1718133e-03 -1.6678020e-03  7.3462212e-04 -7.4729859e-04\n",
            " -3.8771071e-03  1.1272669e-03 -2.6914792e-03  5.1522953e-04\n",
            " -4.3058125e-03 -3.1473336e-03 -4.8869541e-03  3.8554654e-03\n",
            "  2.6356771e-03  3.7084839e-03  2.2752613e-03  2.4561735e-03\n",
            "  4.4918037e-03 -2.7590632e-03 -2.1647902e-03 -4.6999585e-03\n",
            "  3.0373712e-03 -3.4747936e-03  2.1573119e-03  1.6551111e-04\n",
            "  3.1210128e-03 -2.5814828e-03 -8.2925882e-04  1.6824902e-03\n",
            " -7.4863853e-04 -4.4723195e-03 -1.2846669e-03  3.2959061e-03]\n",
            "Word2Vec(vocab=48, size=100, alpha=0.025)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:23: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# IMDB dataset classification using tf keras utils and sequential model\n",
        "\n",
        "import numpy as np\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from keras import models\n",
        "from keras import layers\n",
        "from keras.datasets import imdb\n",
        " \n",
        "(train_data, train_target), (test_data, test_target) = imdb.load_data(num_words=10000)\n",
        "dt = np.concatenate((train_data, test_data), axis=0)\n",
        "tar = np.concatenate((train_target, test_target), axis=0)\n",
        " \n",
        "def convert(sequences, dimension = 10000):\n",
        " results = np.zeros((len(sequences), dimension))\n",
        " for i, sequence in enumerate(sequences):\n",
        "  results[i, sequence] = 1\n",
        " return results\n",
        " \n",
        "dt = convert(dt)\n",
        "tar = np.array(tar).astype(\"float32\")\n",
        "test_x = dt[:9000]\n",
        "test_y = tar[:9000]\n",
        "train_x = dt[9000:]\n",
        "train_y = tar[9000:]\n",
        "model = models.Sequential()\n",
        "# Input - Layer\n",
        "model.add(layers.Dense(50, activation = \"relu\", input_shape=(10000, )))\n",
        "# Hidden - Layers\n",
        "model.add(layers.Dropout(0.4, noise_shape=None, seed=None))\n",
        "model.add(layers.Dense(50, activation = \"relu\"))\n",
        "model.add(layers.Dropout(0.3, noise_shape=None, seed=None))\n",
        "model.add(layers.Dense(50, activation = \"relu\"))\n",
        "# Output- Layer\n",
        "model.add(layers.Dense(1, activation = \"sigmoid\"))\n",
        "model.summary()\n",
        "# compiling the model\n",
        " \n",
        "model.compile(\n",
        " optimizer = \"adam\",\n",
        " loss = \"binary_crossentropy\",\n",
        " metrics = [\"accuracy\"]\n",
        ")\n",
        "results = model.fit(\n",
        " train_x, train_y,\n",
        " epochs= 2,\n",
        " batch_size = 500,\n",
        " validation_data = (test_x, test_y)\n",
        ")\n",
        "print(\"Test-Accuracy:\", np.mean(results.history[\"val_accuracy\"]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ApPJdi2jz7q7",
        "outputId": "7307904d-3dd2-4272-99c0-6169345032a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_8 (Dense)             (None, 50)                500050    \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 50)                0         \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 50)                2550      \n",
            "                                                                 \n",
            " dropout_5 (Dropout)         (None, 50)                0         \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 50)                2550      \n",
            "                                                                 \n",
            " dense_11 (Dense)            (None, 1)                 51        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 505,201\n",
            "Trainable params: 505,201\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/2\n",
            "82/82 [==============================] - 5s 57ms/step - loss: 0.4242 - accuracy: 0.8038 - val_loss: 0.2628 - val_accuracy: 0.8943\n",
            "Epoch 2/2\n",
            "82/82 [==============================] - 5s 58ms/step - loss: 0.2309 - accuracy: 0.9140 - val_loss: 0.2596 - val_accuracy: 0.8953\n",
            "Test-Accuracy: 0.8948333561420441\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import HTML, display\n",
        "\n",
        "def set_css():\n",
        "  display(HTML('''\n",
        "  <style>\n",
        "    pre {\n",
        "        white-space: pre-wrap;\n",
        "    }\n",
        "  </style>\n",
        "  '''))\n",
        "get_ipython().events.register('pre_run_cell', set_css)"
      ],
      "metadata": {
        "id": "wHybcMHil52E"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "para = \"The endless source of knowledge, information, entertainment, and training are books. Before the age of the internet, books were the most dominating source of knowledge. But of course, with technology, the forms of books have changed, and books have become more accessible to everyone. Regardless of all other supplements of books, the contribution and role of books in our life are indispensable. In the education system, books are mostly followed to date for knowledge providing and gain. Books on several subjects enhance several aspects of education and learning. Writers can express their thoughts, views, and observations about any topic through their writings, which are published in books.\"\n",
        "para"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "id": "rB8LcCGUldO8",
        "outputId": "3b3e1dda-0475-4e7d-c5b7-4c099245878c"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The endless source of knowledge, information, entertainment, and training are books. Before the age of the internet, books were the most dominating source of knowledge. But of course, with technology, the forms of books have changed, and books have become more accessible to everyone. Regardless of all other supplements of books, the contribution and role of books in our life are indispensable. In the education system, books are mostly followed to date for knowledge providing and gain. Books on several subjects enhance several aspects of education and learning. Writers can express their thoughts, views, and observations about any topic through their writings, which are published in books.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sent_list = nltk.sent_tokenize(para)\n",
        "sent_list"
      ],
      "metadata": {
        "id": "5CwF7cqp0QiB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138
        },
        "outputId": "70c0977d-88e1-4f05-91e6-2a023f996321"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['The endless source of knowledge, information, entertainment, and training are books.',\n",
              " 'Before the age of the internet, books were the most dominating source of knowledge.',\n",
              " 'But of course, with technology, the forms of books have changed, and books have become more accessible to everyone.',\n",
              " 'Regardless of all other supplements of books, the contribution and role of books in our life are indispensable.',\n",
              " 'In the education system, books are mostly followed to date for knowledge providing and gain.',\n",
              " 'Books on several subjects enhance several aspects of education and learning.',\n",
              " 'Writers can express their thoughts, views, and observations about any topic through their writings, which are published in books.']"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "post_punctuation = []\n",
        "for sentences in sent_list:\n",
        "  sent = punctuation.sub(\" \", sentences)\n",
        "  if len(sent)>0:\n",
        "    post_punctuation.append(sent)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "smz6V9WRjfqh",
        "outputId": "2db4623c-6c4a-451a-da73-7bf4caa87052"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "formatted_str = ' '.join([str(pp) for pp in post_punctuation])\n",
        "formatted_str"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "id": "q_7BZqEYjutA",
        "outputId": "ca276328-960c-4c7c-dc8f-0a9e02ea0c14"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The endless source of knowledge  information  entertainment  and training are books  Before the age of the internet  books were the most dominating source of knowledge  But of course  with technology  the forms of books have changed  and books have become more accessible to everyone  Regardless of all other supplements of books  the contribution and role of books in our life are indispensable  In the education system  books are mostly followed to date for knowledge providing and gain  Books on several subjects enhance several aspects of education and learning  Writers can express their thoughts  views  and observations about any topic through their writings  which are published in books '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stopwords = nltk.corpus.stopwords.words('english')\n",
        "\n",
        "word_frequencies = {}\n",
        "for word in nltk.word_tokenize(formatted_str):\n",
        "    if word not in stopwords:\n",
        "        if word not in word_frequencies.keys():\n",
        "            word_frequencies[word] = 1\n",
        "        else:\n",
        "            word_frequencies[word] += 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "0MrElrqPjwwk",
        "outputId": "d758d923-820f-4660-88eb-58c1b05ca0ed"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word_frequencies"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 850
        },
        "id": "epUj0F_VkDAw",
        "outputId": "871e359b-2f5a-46e2-fa7f-1958611b4bdd"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Before': 1,\n",
              " 'Books': 1,\n",
              " 'But': 1,\n",
              " 'In': 1,\n",
              " 'Regardless': 1,\n",
              " 'The': 1,\n",
              " 'Writers': 1,\n",
              " 'accessible': 1,\n",
              " 'age': 1,\n",
              " 'aspects': 1,\n",
              " 'become': 1,\n",
              " 'books': 8,\n",
              " 'changed': 1,\n",
              " 'contribution': 1,\n",
              " 'course': 1,\n",
              " 'date': 1,\n",
              " 'dominating': 1,\n",
              " 'education': 2,\n",
              " 'endless': 1,\n",
              " 'enhance': 1,\n",
              " 'entertainment': 1,\n",
              " 'everyone': 1,\n",
              " 'express': 1,\n",
              " 'followed': 1,\n",
              " 'forms': 1,\n",
              " 'gain': 1,\n",
              " 'indispensable': 1,\n",
              " 'information': 1,\n",
              " 'internet': 1,\n",
              " 'knowledge': 3,\n",
              " 'learning': 1,\n",
              " 'life': 1,\n",
              " 'mostly': 1,\n",
              " 'observations': 1,\n",
              " 'providing': 1,\n",
              " 'published': 1,\n",
              " 'role': 1,\n",
              " 'several': 2,\n",
              " 'source': 2,\n",
              " 'subjects': 1,\n",
              " 'supplements': 1,\n",
              " 'system': 1,\n",
              " 'technology': 1,\n",
              " 'thoughts': 1,\n",
              " 'topic': 1,\n",
              " 'training': 1,\n",
              " 'views': 1,\n",
              " 'writings': 1}"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "maximum_frequncy = max(word_frequencies.values())\n",
        "\n",
        "for word in word_frequencies.keys():\n",
        "    word_frequencies[word] = (word_frequencies[word]/maximum_frequncy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "gMIWS78xkIjI",
        "outputId": "328ebd1c-faac-4561-e049-cf509d990cf3"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence_scores = {}\n",
        "for sent in sent_list:\n",
        "    for word in nltk.word_tokenize(sent.lower()):\n",
        "        if word in word_frequencies.keys():\n",
        "            if len(sent.split(' ')) < 30:\n",
        "                if sent not in sentence_scores.keys():\n",
        "                    sentence_scores[sent] = word_frequencies[word]\n",
        "                else:\n",
        "                    sentence_scores[sent] += word_frequencies[word]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "2a8mBFWrkt4L",
        "outputId": "478b5a24-6f00-4424-9674-8274dc7291c3"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence_scores"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138
        },
        "id": "HOh48Genk0P-",
        "outputId": "4e2dbb62-c8c0-4645-8aaf-d6c168133af3"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Before the age of the internet, books were the most dominating source of knowledge.': 2.0,\n",
              " 'Books on several subjects enhance several aspects of education and learning.': 2.25,\n",
              " 'But of course, with technology, the forms of books have changed, and books have become more accessible to everyone.': 2.875,\n",
              " 'In the education system, books are mostly followed to date for knowledge providing and gain.': 2.375,\n",
              " 'Regardless of all other supplements of books, the contribution and role of books in our life are indispensable.': 2.625,\n",
              " 'The endless source of knowledge, information, entertainment, and training are books.': 2.125,\n",
              " 'Writers can express their thoughts, views, and observations about any topic through their writings, which are published in books.': 1.875}"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import heapq\n",
        "summary_sentences = heapq.nlargest(7, sentence_scores, key=sentence_scores.get)\n",
        "\n",
        "summary = ' '.join(summary_sentences)\n",
        "print(summary)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "id": "8dirnd5Xk1vT",
        "outputId": "5d00baae-6bfc-4fda-ab6f-cb474f89597e"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "But of course, with technology, the forms of books have changed, and books have become more accessible to everyone. Regardless of all other supplements of books, the contribution and role of books in our life are indispensable. In the education system, books are mostly followed to date for knowledge providing and gain. Books on several subjects enhance several aspects of education and learning. The endless source of knowledge, information, entertainment, and training are books. Before the age of the internet, books were the most dominating source of knowledge. Writers can express their thoughts, views, and observations about any topic through their writings, which are published in books.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "reference from - https://stackabuse.com/text-summarization-with-nltk-in-python/"
      ],
      "metadata": {
        "id": "XURYDyc_lL7Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import word_tokenize, sent_tokenize\n",
        "import heapq\n",
        "import nltk\n",
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "# n - number of lines for summary to be generated , para - paragraph to be summarized \n",
        "\n",
        "def generateSummary(n, para):\n",
        "  sent_list = nltk.sent_tokenize(para)\n",
        "  if n>len(sent_list):\n",
        "    return \"Summary cannot be greater in length than provided data!\"\n",
        "  post_punctuation = [] \n",
        "  punctuation = re.compile(r'[-.?!,:;()|0-9]')\n",
        "  for sentences in sent_list:\n",
        "    sent = punctuation.sub(\" \", sentences)\n",
        "    sent = re.sub(r'\\[[0-9]*\\]', ' ', sentences)\n",
        "    sent = re.sub(r'\\s+', ' ', sentences)\n",
        "    if len(sent)>0:\n",
        "      post_punctuation.append(sent)\n",
        "  \n",
        "  formatted_str = ' '.join([str(pp) for pp in post_punctuation])\n",
        "  stopwords = nltk.corpus.stopwords.words('english')\n",
        "\n",
        "  word_frequencies = {}\n",
        "  for word in nltk.word_tokenize(formatted_str):\n",
        "      if word not in stopwords:\n",
        "          if word not in word_frequencies.keys():\n",
        "              word_frequencies[word] = 1\n",
        "          else:\n",
        "              word_frequencies[word] += 1\n",
        "\n",
        "  maximum_frequncy = max(word_frequencies.values())\n",
        "\n",
        "  for word in word_frequencies.keys():\n",
        "      word_frequencies[word] = (word_frequencies[word]/maximum_frequncy)  \n",
        "\n",
        "  sentence_scores = {}\n",
        "  for sent in sent_list:\n",
        "      for word in nltk.word_tokenize(sent.lower()):\n",
        "          if word in word_frequencies.keys():\n",
        "              if len(sent.split(' ')) < 30:\n",
        "                  if sent not in sentence_scores.keys():\n",
        "                      sentence_scores[sent] = word_frequencies[word]\n",
        "                  else:\n",
        "                      sentence_scores[sent] += word_frequencies[word]  \n",
        "\n",
        "  summary_sentences = heapq.nlargest(n, sentence_scores, key=sentence_scores.get)\n",
        "\n",
        "  summary = ' '.join(summary_sentences)\n",
        "  return summary"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "auwRHuO5mvnB",
        "outputId": "3a2b0994-2e03-4dfd-a525-4af0d0e97343"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "para1 = \"France (French: [fʁɑ̃s] Listen), officially the French Republic (French: République française[12]), is a transcontinental country spanning Western Europe and overseas regions and territories in the Americas and the Atlantic, Pacific and Indian Oceans.[XII] Its metropolitan area extends from the Rhine to the Atlantic Ocean and from the Mediterranean Sea to the English Channel and the North Sea; overseas territories include French Guiana in South America, Saint Pierre and Miquelon in the North Atlantic, the French West Indies, and many islands in Oceania and the Indian Ocean. Due to its several coastal territories, France has the largest exclusive economic zone in the world. France borders Belgium, Luxembourg, Germany, Switzerland, Monaco, Italy, Andorra and Spain in Europe, as well as the Netherlands, Suriname and Brazil in the Americas. Its eighteen integral regions (five of which are overseas) span a combined area of 643,801 km2 (248,573 sq mi) and over 67 million people (as of May 2021).[3] France is a unitary semi-presidential republic with its capital in Paris, the country's largest city and main cultural and commercial centre; other major urban areas include Marseille, Lyon, Toulouse, Lille, Bordeaux, and Nice. Inhabited since the Palaeolithic era, the territory of Metropolitan France was settled by Celtic tribes known as Gauls during the Iron Age. Rome annexed the area in 51 BC, leading to a distinct Gallo-Roman culture that laid the foundation of the French language. The Germanic Franks formed the Kingdom of Francia, which became the heartland of the Carolingian Empire. The Treaty of Verdun of 843 partitioned the empire, with West Francia becoming the Kingdom of France in 987. In the High Middle Ages, France was a powerful but highly decentralised feudal kingdom. Philip II successfully strengthened royal power and defeated his rivals to double the size of the crown lands; by the end of his reign, France had emerged as the most powerful state in Europe. From the mid-14th to the mid-15th century, France was plunged into a series of dynastic conflicts involving England, collectively known as the Hundred Years' War, and a distinct French identity emerged as a result. The French Renaissance saw art and culture flourish, conflict with the House of Habsburg, and the establishment of a global colonial empire, which by the 20th century would become the second-largest in the world.[13] The second half of the 16th century was dominated by religious civil wars between Catholics and Huguenots that severely weakened the country. France again emerged as Europe's dominant power in the 17th century under Louis XIV following the Thirty Years' War.[14] Inadequate economic policies, inequitable taxes and frequent wars (notably a defeat in the Seven Years' War and costly involvement in the American War of Independence), left the kingdom in a precarious economic situation by the end of the 18th century. This precipitated the French Revolution of 1789, which overthrew the Ancien Régime and produced the Declaration of the Rights of Man, which expresses the nation's ideals to this day.\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "AnFooJbind0D",
        "outputId": "2e1dce19-610a-4b5d-c4d7-2fcc713bce44"
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(generateSummary(9, para1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138
        },
        "id": "3MFttqpjoA1M",
        "outputId": "9baf7226-6fea-448a-cdc4-fbc8ba72701d"
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "France borders Belgium, Luxembourg, Germany, Switzerland, Monaco, Italy, Andorra and Spain in Europe, as well as the Netherlands, Suriname and Brazil in the Americas. This precipitated the French Revolution of 1789, which overthrew the Ancien Régime and produced the Declaration of the Rights of Man, which expresses the nation's ideals to this day. Its eighteen integral regions (five of which are overseas) span a combined area of 643,801 km2 (248,573 sq mi) and over 67 million people (as of May 2021). Due to its several coastal territories, France has the largest exclusive economic zone in the world. Rome annexed the area in 51 BC, leading to a distinct Gallo-Roman culture that laid the foundation of the French language. The Treaty of Verdun of 843 partitioned the empire, with West Francia becoming the Kingdom of France in 987. Inhabited since the Palaeolithic era, the territory of Metropolitan France was settled by Celtic tribes known as Gauls during the Iron Age. The Germanic Franks formed the Kingdom of Francia, which became the heartland of the Carolingian Empire. In the High Middle Ages, France was a powerful but highly decentralised feudal kingdom.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "TQ1p8wdpoDyw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}